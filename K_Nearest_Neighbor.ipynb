{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcwaoeSRisPmhKNz28/cL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2022yingjie/Machine_Learning-xitutu/blob/main/K_Nearest_Neighbor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkp0-CvR9F27"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.基本概念\n",
        "> 1.1 K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是上面所说的K个邻居），这K个实例的多数属于某个类，就把该输入实例分类到这个类中。\n",
        "\n",
        "> 1.2 问题背景：最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是如果一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于上述问题就产生了KNN。\n",
        "\n",
        "# 2.常见的距离度量\n",
        "> 2.1 欧式距离(Euclidean distance)\n",
        ">> 两点之间的坐标距离，定义在欧氏空间当中，公式如下：$$d(X,Y)=\\sqrt{(x_{1}-y_{1})^{2}+(x_{2}-y_{2})^{2}+...+(x_{n}-y_{n})^{2}}$$\n",
        "\n",
        "> 2.2 曼哈顿距离\n",
        ">> 定义曼哈顿距离是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和,公式如下：$$d(X,Y)=\\sum_{n=1}^{N}|x_{n}-y_{n}|$$\n",
        "\n",
        "> 2.3 余弦夹角\n",
        ">> 几何中夹角余弦可用来衡量两个向量方向的差异，机器学习中借用这一概念来衡量样本向量之间的差异，公式如下：$$cosθ=\\frac{X*Y}{|X||Y|}$$\n",
        ">> 夹角余弦取值范围为[-1,1]。夹角余弦越大表示两个向量的夹角越小，夹角余弦越小表示两向量的夹角越大。当两个向量的方向重合时夹角余弦取最大值1，当两个向量的方向完全相反夹角余弦取最小值-1。\n",
        "\n",
        "# 3.算法描述\n",
        "* 计算测试数据和各个训练数据之间的距离；\n",
        "* 对所有距离值进行排序，可以选择升序或降序；\n",
        "* 选择前K个距离最小的点；\n",
        "* 计算前K个点中所在类别出现的频率；\n",
        "* 返回最高频率的类别作为当前测试数据的预测分类。\n",
        "\n",
        "# 4.K值的选择\n",
        "* 选用较小的K值：相当于用较小的领域中的训练实例进行预测，只有与测试数据相近的实例才会对分类结果起作用，也就是K值小容易过拟合。\n",
        "* 选用较大的K值：与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，导致欠拟合。\n",
        "* 选用K=N：则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的累，模型过于简单，忽略了训练实例中大量有用信息。\n",
        "\n",
        "# 5.K近邻的实现：KD树\n",
        ">5.1 在实现K近邻的时候，最主要问题是考虑如何实现快速K近邻搜索。在特征空间维度较大或者训练数据多的时候有其必要。因为普通的K近邻实现是线性扫描，计算输入与每一个训练实例之间的距离，当训练集很大时耗时。\n",
        "\n",
        ">5.2 KD树是一种二叉树。表示对K维空间的一种划分，构造KD树就是不断用垂直于坐标轴的超平面将K维空间切分的过程，左右子树分别为划分出的K维超矩形区域。\n",
        "\n",
        ">5.3 算法流程（平衡KD树，即依次选择坐标轴对空间进行切分）\n",
        "* K维度空间数据集$T=\\{x_{1},x_{2},...,x_{N}\\}$，其中$x_{i}=(x_{i}^{1},x_{i}^{2},...,x_{i}^{k})^{T},i=1,2,...,N$\n",
        "* 选择$x^{1}$维度上的中位数点作为当前根结点(如果是偶数则选择两边)，在该维度$x_{i}^{1}<x_{m}^{1}$分左子区域，$x_{i}^{1}>x_{m}^{1}$分右子区域；\n",
        "* 重复切分，第j次切分(深度)选择第j个维度，如果$j>K$,则选择第$j(mod K)+1$维度；\n",
        "* 直到左右子区域无可划分，KD树构建完成。\n",
        "\n",
        "# 6.搜索KD树\n",
        "* 这个方法用于在KD树中找到最接近给定点的点。\n",
        "* 它首先检查根节点是否为空，如果是，则返回当前最佳点。\n",
        "* 选择一个轴基于当前深度，然后确定搜索路径：如果给定点在轴上的值小于根节点的值，* 则先搜索左子树，否则搜索右子树。\n",
        "* 如果在相应的分支中找到更接近的点，则更新最佳点。\n",
        "* 如果另一分支有可能包含更近的点（通过比较轴上的距离），则在那个分支上也进行搜索。\n",
        "\n",
        "# 7.KD树的示例代码\n",
        ">7.1 Node 类:\n",
        "这是一个简单的节点类，用于表示KD树中的每个节点。\n",
        "它有三个属性：point（节点存储的点），left（指向左子树的指针），和right（指向右子树的指针）。\n",
        "\n",
        ">7.2 KDTree 类:\n",
        "这个类用于构建和操作KD树。\n",
        "它有一个初始化方法（__init__），接受一个点的列表作为输入，并使用build_tree方法来构建树。\n",
        "\n",
        "\n",
        ">7.3 构建树\n",
        "build_tree 方法:\n",
        "这个方法递归地构建KD树。\n",
        "它首先检查点的列表是否为空，如果为空，则返回None。\n",
        "根据当前的深度（depth），选择一个轴（axis）来分割点。这里使用了模运算符（%）来在各个维度之间循环。\n",
        "点列表根据选定的轴排序，然后选择中位数作为根节点。\n",
        "最后，递归地为左侧和右侧的点集创建子树。\n",
        "\n",
        "\n",
        "> 7.4 搜索最近邻点\n",
        "closest_point 方法:\n",
        "这个方法用于在KD树中找到最接近给定点的点。\n",
        "它首先检查根节点是否为空，如果是，则返回当前最佳点。\n",
        "选择一个轴基于当前深度，然后确定搜索路径：如果给定点在轴上的值小于根节点的值，则先搜索左子树，否则搜索右子树。\n",
        "如果在相应的分支中找到更接近的点，则更新最佳点。\n",
        "如果另一分支有可能包含更近的点（通过比较轴上的距离），则在那个分支上也进行搜索。\n",
        "\n",
        "> 7.5 closest_point_helper 方法:\n",
        "这是一个辅助递归方法，用于在closest_point方法中进行实际的搜索。\n",
        "它的逻辑与closest_point类似，但是操作在非根节点上。\n",
        "\n",
        "> 7.6 静态方法 distance:\n",
        "这是一个静态方法，用于计算两点之间的欧几里得距离。\n",
        "\n"
      ],
      "metadata": {
        "id": "D2G4Dcpr9NNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 算法流程\n",
        "# 1. 计算向量之间的距离\n",
        "# 2. 用sorted函数排序，取前K个\n",
        "\n",
        "# Example, point cloud，求每个点的K近邻\n",
        "import numpy as np\n",
        "import torch\n",
        "N=500\n",
        "point_cloud = torch.randn((N,3))\n",
        "print(point_cloud)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4GGsDiuSQYk",
        "outputId": "a2e2d1ab-11aa-4476-de54-c2a4c1e9aafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2035, -1.6443, -0.7201],\n",
            "        [-1.5781, -0.0844, -0.7286],\n",
            "        [ 0.0064,  1.0430, -2.6314],\n",
            "        ...,\n",
            "        [-0.3669, -1.1512, -0.2094],\n",
            "        [-1.2366, -0.3461, -0.9010],\n",
            "        [ 2.9251, -0.8772, -0.4081]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def CalDis(p,pc,K=16):\n",
        "  dis_mat = torch.sum((p - pc)**2,dim=1)\n",
        "  print(\"dis_mat:\",dis_mat.shape)\n",
        "  dis_mat_index = dis_mat.topk(k=K,largest=False,dim=0)\n",
        "  print(\"dis_mat_index:\",dis_mat_index)# topk返回两个值，一个是前K个最小值，一个是这K个最小值对应的索引\n",
        "  assert 1==2\n",
        "def FindKNN(array, K=16):\n",
        "  # pc.shape (N,3)\n",
        "  Neighbor_index = []\n",
        "  for p in pc:\n",
        "    dis_p_index = CalDis(p,pc,K)\n",
        "    Neighbor_index.append(dis_p_index)\n",
        "  print(np.array(Neighbor_index).shape)\n",
        "\n",
        "\n",
        "pc = point_cloud\n",
        "FindKNN(pc,K=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "nY85QJkqTGB3",
        "outputId": "105edf11-148c-4a51-ae77-ea4db56e6ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dis_mat: torch.Size([500])\n",
            "dis_mat_index: torch.return_types.topk(\n",
            "values=tensor([0.0000, 0.0929, 0.2486, 0.2533, 0.3339, 0.4139, 0.4203, 0.4430, 0.4543,\n",
            "        0.5558, 0.5655, 0.5751, 0.6286, 0.6885, 0.7098, 0.7582]),\n",
            "indices=tensor([  0, 149, 271, 265,  28, 164, 123, 136, 474,  95, 244,  89, 248, 134,\n",
            "        105, 199]))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3068c86a1e47>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mFindKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-3068c86a1e47>\u001b[0m in \u001b[0;36mFindKNN\u001b[0;34m(array, K)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mNeighbor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdis_p_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCalDis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mNeighbor_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_p_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeighbor_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-3068c86a1e47>\u001b[0m in \u001b[0;36mCalDis\u001b[0;34m(p, pc, K)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdis_mat_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dis_mat_index:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdis_mat_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mFindKNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# pc.shape (N,3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, point, left=None, right=None):\n",
        "        self.point = point\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "class KDTree:\n",
        "    def __init__(self, points):\n",
        "        self.root = self.build_tree(points, depth=0)\n",
        "\n",
        "    def build_tree(self, points, depth):\n",
        "        if not points:\n",
        "            return None\n",
        "\n",
        "        # Select axis based on depth so that axis cycles over all valid values\n",
        "        k = len(points[0]) # Assumes all points have the same dimension\n",
        "        axis = depth % k\n",
        "\n",
        "        # Sort point list and choose median as pivot element\n",
        "        points.sort(key=lambda x: x[axis])\n",
        "        median = len(points) // 2\n",
        "\n",
        "        # Create node and construct subtrees\n",
        "        return Node(\n",
        "            point=points[median],\n",
        "            left=self.build_tree(points[:median], depth + 1),\n",
        "            right=self.build_tree(points[median+1:], depth + 1)\n",
        "        )\n",
        "\n",
        "    def closest_point(self, point, depth=0, best=None):\n",
        "        if self.root is None:\n",
        "            return best\n",
        "\n",
        "        if best is None or self.distance(point, best.point) > self.distance(point, self.root.point):\n",
        "            best = self.root\n",
        "\n",
        "        # Select axis based on depth\n",
        "        k = len(point)\n",
        "        axis = depth % k\n",
        "\n",
        "        next_branch = None\n",
        "        opposite_branch = None\n",
        "\n",
        "        if point[axis] < self.root.point[axis]:\n",
        "            next_branch = self.root.left\n",
        "            opposite_branch = self.root.right\n",
        "        else:\n",
        "            next_branch = self.root.right\n",
        "            opposite_branch = self.root.left\n",
        "\n",
        "        if next_branch is not None:\n",
        "            best = self.closest_point_helper(point, next_branch, depth+1, best)\n",
        "\n",
        "        if opposite_branch is not None:\n",
        "            if self.distance(point, best.point) > abs(point[axis] - self.root.point[axis]):\n",
        "                best = self.closest_point_helper(point, opposite_branch, depth+1, best)\n",
        "\n",
        "        return best\n",
        "\n",
        "    def closest_point_helper(self, point, node, depth, best):\n",
        "        if node is None:\n",
        "            return best\n",
        "\n",
        "        if self.distance(point, node.point) < self.distance(point, best.point):\n",
        "            best = node\n",
        "\n",
        "        # Select axis based on depth\n",
        "        k = len(point)\n",
        "        axis = depth % k\n",
        "\n",
        "        next_branch = None\n",
        "        opposite_branch = None\n",
        "\n",
        "        if point[axis] < node.point[axis]:\n",
        "            next_branch = node.left\n",
        "            opposite_branch = node.right\n",
        "        else:\n",
        "            next_branch = node.right\n",
        "            opposite_branch = node.left\n",
        "\n",
        "        if next_branch is not None:\n",
        "            best = self.closest_point_helper(point, next_branch, depth+1, best)\n",
        "\n",
        "        if opposite_branch is not None:\n",
        "            if self.distance(point, best.point) > abs(point[axis] - node.point[axis]):\n",
        "                best = self.closest_point_helper(point, opposite_branch, depth+1, best)\n",
        "\n",
        "        return best\n",
        "\n",
        "    @staticmethod\n",
        "    def distance(point1, point2):\n",
        "        return sum((x - y) ** 2 for x, y in zip(point1, point2)) ** 0.5\n",
        "\n",
        "# Example usage\n",
        "points = [[2, 3], [5, 4], [9, 6], [4, 7], [8, 1], [7, 2]]\n",
        "kdtree = KDTree(points)\n",
        "point = [3, 4.5]\n",
        "closest = kdtree.closest_point(point)\n",
        "print(\"Closest point to\", point, \"is\", closest.point)\n"
      ],
      "metadata": {
        "id": "99DN_4EaMjaP",
        "outputId": "785b3295-5c04-41d0-f737-252cce36c7d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest point to [3, 4.5] is [2, 3]\n"
          ]
        }
      ]
    }
  ]
}